{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c79872fc",
   "metadata": {},
   "source": [
    "# Pull data from World Bank WDI and save to local CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21508728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved WDI data to ../data/raw/economic_dev_2000_2023.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pull data from World Bank WDI and save to local CSV\n",
    "\n",
    "Dependencies:\n",
    "    pip install wbgapi pandas\n",
    "\"\"\"\n",
    "\n",
    "import wbgapi as wb\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def fetch_and_save_wdi(\n",
    "    indicators: list,\n",
    "    countries: list = None,\n",
    "    years: list = None,\n",
    "    output_dir: str = \"data/raw\",\n",
    "    output_filename: str = \"wdi_data.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch World Bank WDI data and save as CSV.\n",
    "\n",
    "    Parameters:\n",
    "        indicators: List of indicator codes, e.g. [\"NY.GDP.PCAP.KD\", \"SL.EMP.TOTL.SP.ZS\", \"NY.GDP.MKTP.KD.ZG\"]\n",
    "        countries: List of country ISO-2/ISO-3 codes, default None means all available countries\n",
    "        years: List of year range, e.g. list(range(2000, 2024))\n",
    "        output_dir: Local save directory\n",
    "        output_filename: Output file name\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if countries is None:\n",
    "        countries = wb.economy.list()  # Get codes for all economies\n",
    "\n",
    "    # If years not specified, use 1960–latest\n",
    "    if years is None:\n",
    "        years = list(range(1960, pd.Timestamp.now().year + 1))\n",
    "\n",
    "    # Fetch data: DataFrame with row index (economy, year), columns as indicators\n",
    "    df = wb.data.DataFrame(\n",
    "        indicators,\n",
    "        economy=countries,\n",
    "        time=years,\n",
    "        labels=True\n",
    "    )\n",
    "\n",
    "    # Reset index, convert economy and time to regular columns\n",
    "    df = df.reset_index().rename(columns={\"economy\": \"country\", \"time\": \"year\"})\n",
    "\n",
    "    # Save as CSV (no index column)\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"Saved WDI data to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    indicators = [\n",
    "        \"NY.GDP.PCAP.KD\",\n",
    "        \"SL.EMP.TOTL.SP.ZS\",\n",
    "        \"NY.GDP.MKTP.KD.ZG\"\n",
    "    ]\n",
    "\n",
    "    # [\"USA\",\"CHN\",\"IND\"]\n",
    "    countries = [\"USA\", \"CHN\", \"IND\"]\n",
    "\n",
    "    # Specify year range\n",
    "    years = list(range(2000, 2024))\n",
    "\n",
    "    # Execute fetch and save\n",
    "    fetch_and_save_wdi(\n",
    "        indicators=indicators,\n",
    "        countries=countries,\n",
    "        years=years,\n",
    "        output_dir=\"../data/raw\",\n",
    "        output_filename=\"economic_dev_2000_2023.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb4c935",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d3c6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data saved to ../data/clean/wdi_long_clean.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use DuckDB in Python to perform SQL cleaning/unpivoting of WDI wide table, and export long-format CSV.\n",
    "Dependencies:\n",
    "    pip install duckdb pandas\n",
    "\"\"\"\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "RAW_CSV        = \"../data/raw/economic_dev_2000_2023.csv\"\n",
    "OUTPUT_CSV     = \"../data/clean/wdi_long_clean.csv\"\n",
    "DB_FILE        = \"../data/tmp/wdi.duckdb\"\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(DB_FILE), exist_ok=True)\n",
    "\n",
    "# 1) Connect to DuckDB (file storage), or create in-memory database with \":memory:\"\n",
    "con = duckdb.connect(database=DB_FILE, read_only=False)\n",
    "\n",
    "# 2) Read CSV into a DuckDB table raw_widi, rename to avoid case conflicts in SELECT\n",
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE raw_wdi AS\n",
    "SELECT\n",
    "    country        AS country_code,\n",
    "    series         AS indicator_code,\n",
    "    \"Country\"      AS country_name,\n",
    "    \"Series\"       AS indicator_name,\n",
    "    YR2000, YR2001, YR2002, YR2003, YR2004, YR2005,\n",
    "    YR2006, YR2007, YR2008, YR2009, YR2010, YR2011,\n",
    "    YR2012, YR2013, YR2014, YR2015, YR2016, YR2017,\n",
    "    YR2018, YR2019, YR2020, YR2021, YR2022, YR2023\n",
    "FROM read_csv_auto('{RAW_CSV}');\n",
    "\"\"\")\n",
    "\n",
    "# 3) Use SQL UNPIVOT to transform wide table to long table, filter out NULLs\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE clean_wdi AS\n",
    "SELECT\n",
    "    country_code,\n",
    "    indicator_code,\n",
    "    country_name,\n",
    "    indicator_name,\n",
    "    CAST(REPLACE(col, 'YR', '') AS INTEGER) AS year,\n",
    "    value\n",
    "FROM raw_wdi\n",
    "UNPIVOT (\n",
    "    value FOR col IN (\n",
    "        YR2000, YR2001, YR2002, YR2003, YR2004, YR2005,\n",
    "        YR2006, YR2007, YR2008, YR2009, YR2010, YR2011,\n",
    "        YR2012, YR2013, YR2014, YR2015, YR2016, YR2017,\n",
    "        YR2018, YR2019, YR2020, YR2021, YR2022, YR2023\n",
    "    )\n",
    ")\n",
    "WHERE value IS NOT NULL\n",
    "ORDER BY country_code, indicator_code, year;\n",
    "\"\"\")\n",
    "\n",
    "# 4) Export cleaned long table to local CSV\n",
    "df_clean = con.execute(\"SELECT * FROM clean_wdi\").df()\n",
    "df_clean.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "con.close()\n",
    "print(\"Clean data saved to\", OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf67ebe",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c652e1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved exploratory analysis complete; figures saved to ../figures/exploratory\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "INPUT_CSV = \"../data/clean/wdi_long_clean.csv\"\n",
    "FIGURES_DIR = \"../figures/exploratory\"\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Descriptive statistics table (as before)\n",
    "desc = df.groupby(['indicator_code','country_code'])['value'].describe().round(2)\n",
    "desc.to_csv(os.path.join(FIGURES_DIR, \"descriptive_stats.csv\"))\n",
    "pivot_mean = df.groupby(['country_code','indicator_code'])['value'].mean().unstack().round(2)\n",
    "pivot_mean.to_csv(os.path.join(FIGURES_DIR, \"mean_pivot.csv\"))\n",
    "\n",
    "# 1. Trend line chart: Increase size, mark, annotate last value\n",
    "for indicator in df['indicator_code'].unique():\n",
    "    sub = df[df['indicator_code']==indicator]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for country in sub['country_code'].unique():\n",
    "        csub = sub[sub['country_code']==country]\n",
    "        plt.plot(csub['year'], csub['value'], marker='o', linewidth=2, label=country)\n",
    "        # Annotate last point\n",
    "        last = csub.iloc[-1]\n",
    "        plt.text(last['year'], last['value'], f\"{last['value']:.1f}\", va='bottom', ha='right')\n",
    "    plt.title(f\"Trend of {indicator}\", fontsize=14)\n",
    "    plt.xlabel(\"Year\", fontsize=12)\n",
    "    plt.ylabel(\"Value\", fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Country\")\n",
    "    plt.grid(linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, f\"trend_{indicator}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# 2. Bar comparison for 2023: Show value on bars\n",
    "latest = df[df['year']==df['year'].max()]\n",
    "for indicator in latest['indicator_code'].unique():\n",
    "    sub = latest[latest['indicator_code']==indicator]\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(sub['country_code'], sub['value'])\n",
    "    plt.title(f\"{indicator} in {int(df['year'].max())}\", fontsize=14)\n",
    "    plt.xlabel(\"Country\", fontsize=12)\n",
    "    plt.ylabel(\"Value\", fontsize=12)\n",
    "    # Annotate value at bar top\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, h, f\"{h:.1f}\", ha='center', va='bottom')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, f\"bar_{indicator}_2023.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# 3. Correlation heatmap: Use pcolormesh and add annotations\n",
    "for country in df['country_code'].unique():\n",
    "    sub = df[df['country_code']==country]\n",
    "    wide = sub.pivot(index='year', columns='indicator_code', values='value')\n",
    "    corr = wide.corr()\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    mesh = plt.pcolormesh(corr.values, edgecolors='k', linewidth=0.5)\n",
    "    plt.xticks(range(len(corr)), corr.columns, rotation=45)\n",
    "    plt.yticks(range(len(corr)), corr.index)\n",
    "    plt.title(f\"Indicator Correlation ({country})\", fontsize=14)\n",
    "    # Annotate each cell\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(corr.shape[1]):\n",
    "            plt.text(j + 0.5, i + 0.5, f\"{corr.iloc[i,j]:.2f}\", ha='center', va='center')\n",
    "    plt.colorbar(mesh)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, f\"corr_{country}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# 4. Histogram: Overall distribution of indicators\n",
    "for indicator in df['indicator_code'].unique():\n",
    "    sub = df[df['indicator_code']==indicator]\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(sub['value'], bins=15)\n",
    "    plt.title(f\"Distribution of {indicator}\", fontsize=14)\n",
    "    plt.xlabel(\"Value\", fontsize=12)\n",
    "    plt.ylabel(\"Frequency\", fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, f\"hist_{indicator}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# 5. Boxplot: Compare indicator distribution by country\n",
    "for indicator in df['indicator_code'].unique():\n",
    "    sub = df[df['indicator_code']==indicator]\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    data = [sub[sub['country_code']==c]['value'] for c in sub['country_code'].unique()]\n",
    "    plt.boxplot(data, labels=sub['country_code'].unique())\n",
    "    plt.title(f\"Boxplot of {indicator} by Country\", fontsize=14)\n",
    "    plt.xlabel(\"Country\", fontsize=12)\n",
    "    plt.ylabel(\"Value\", fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, f\"box_{indicator}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# 6. Trend smoothing: Moving average (window=3)\n",
    "for indicator in df['indicator_code'].unique():\n",
    "    sub = df[df['indicator_code']==indicator]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for country in sub['country_code'].unique():\n",
    "        csub = sub[sub['country_code']==country].set_index('year')\n",
    "        smooth = csub['value'].rolling(window=3, center=True).mean()\n",
    "        plt.plot(smooth.index, smooth.values, linewidth=2, label=country)\n",
    "    plt.title(f\"3-Year Moving Avg of {indicator}\", fontsize=14)\n",
    "    plt.xlabel(\"Year\", fontsize=12)\n",
    "    plt.ylabel(\"Smoothed Value\", fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Country\")\n",
    "    plt.grid(linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, f\"smooth_{indicator}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "print(\"Improved exploratory analysis complete; figures saved to\", FIGURES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f40b8",
   "metadata": {},
   "source": [
    "# Modeling and in-depth mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib Chinese support\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans', 'Bitstream Vera Sans', 'sans-serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Configuration\n",
    "INPUT_CSV = \"../data/clean/wdi_long_clean.csv\"\n",
    "MODELS_DIR = \"../models\"\n",
    "FIGURES_DIR = \"../figures/modeling\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Data overview\n",
    "print(\"\\nData overview:\")\n",
    "print(f\"- Number of rows: {df.shape[0]}\")\n",
    "print(f\"- Number of columns: {df.shape[1]}\")\n",
    "print(f\"- Country list: {', '.join(df['country_code'].unique())}\")\n",
    "print(f\"- Indicator list: {', '.join(df['indicator_code'].unique())}\")\n",
    "print(f\"- Year range: {df['year'].min()} - {df['year'].max()}\")\n",
    "\n",
    "# Create wide-format data (each row is a country-year combination, columns are different indicators)\n",
    "def create_wide_df():\n",
    "    \"\"\"Create wide-format data, expanding indicators into columns\"\"\"\n",
    "    # Create a data copy for analysis\n",
    "    wide_df = df.pivot_table(\n",
    "        index=['country_code', 'country_name', 'year'],\n",
    "        columns='indicator_code',\n",
    "        values='value'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Rename columns containing dots to avoid errors in formulas\n",
    "    for col in wide_df.columns:\n",
    "        if isinstance(col, str) and '.' in col:\n",
    "            # Replace dots in indicator codes with underscores\n",
    "            new_col = col.replace('.', '_')\n",
    "            wide_df = wide_df.rename(columns={col: new_col})\n",
    "    \n",
    "    # Create a mapping from indicator code to name\n",
    "    code_to_name = {}\n",
    "    for _, row in df.drop_duplicates(['indicator_code', 'indicator_name']).iterrows():\n",
    "        code = row['indicator_code'].replace('.', '_')\n",
    "        code_to_name[code] = row['indicator_name']\n",
    "    \n",
    "    # Add indicator name columns\n",
    "    for code, name in code_to_name.items():\n",
    "        if code in wide_df.columns:\n",
    "            wide_df[f\"{code}_name\"] = name\n",
    "    \n",
    "    return wide_df, code_to_name\n",
    "\n",
    "wide_df, code_to_name = create_wide_df()\n",
    "print(\"\\nWide-format data sample:\")\n",
    "print(wide_df.head())\n",
    "\n",
    "# Get list of indicator codes\n",
    "indicator_codes = [col for col in wide_df.columns if col in [c.replace('.', '_') for c in df['indicator_code'].unique()]]\n",
    "\n",
    "# Save wide-format data\n",
    "wide_df.to_csv(os.path.join(MODELS_DIR, \"wide_format_data.csv\"), index=False)\n",
    "\n",
    "#####################################################\n",
    "# 1. Linear Regression Analysis - Explore Indicator Relationships\n",
    "#####################################################\n",
    "print(\"\\n\\n1. Performing linear regression analysis...\")\n",
    "\n",
    "def run_linear_regression(X_col, y_col, data, country=None):\n",
    "    \"\"\"Run OLS linear regression and return results\n",
    "    \n",
    "    Args:\n",
    "        X_col: Independent variable column name\n",
    "        y_col: Dependent variable column name\n",
    "        data: DataFrame\n",
    "        country: If specified, analyze only data for this country\n",
    "    \n",
    "    Returns:\n",
    "        Regression result object\n",
    "    \"\"\"\n",
    "    if country:\n",
    "        data = data[data['country_code'] == country]\n",
    "    \n",
    "    # Prepare data\n",
    "    X = data[[X_col]].values\n",
    "    y = data[y_col].values\n",
    "    \n",
    "    # Add constant term\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Fit model\n",
    "    model = sm.OLS(y, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Analyze relationships between all indicator pairs\n",
    "regression_results = {}\n",
    "\n",
    "# Create all possible indicator pair combinations\n",
    "for i, target in enumerate(indicator_codes):\n",
    "    for j, predictor in enumerate(indicator_codes):\n",
    "        if i != j:  # Avoid predicting a variable from itself\n",
    "            key = f\"{target} ~ {predictor}\"\n",
    "            result = run_linear_regression(predictor, target, wide_df)\n",
    "            \n",
    "            # Get coefficients (index 1 because index 0 corresponds to constant term)\n",
    "            coef = result.params[1]\n",
    "            p_val = result.pvalues[1]\n",
    "            \n",
    "            regression_results[key] = {\n",
    "                'coefficient': coef,\n",
    "                'p_value': p_val,\n",
    "                'r_squared': result.rsquared,\n",
    "                'result': result\n",
    "            }\n",
    "            print(f\"Regression {key}: Coefficient = {coef:.4f}, p-value = {p_val:.4f}, R² = {result.rsquared:.4f}\")\n",
    "\n",
    "# Visualize regression lines for each indicator pair\n",
    "for key, res in regression_results.items():\n",
    "    target, predictor = key.split(' ~ ')\n",
    "    result = res['result']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.regplot(x=predictor, y=target, data=wide_df, scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "    \n",
    "    # Get indicator names\n",
    "    target_name = code_to_name.get(target, target)\n",
    "    predictor_name = code_to_name.get(predictor, predictor)\n",
    "    \n",
    "    # Add confidence interval\n",
    "    x_sorted = wide_df[predictor].sort_values()\n",
    "    X_sorted = sm.add_constant(x_sorted)\n",
    "    y_pred = result.predict(X_sorted)\n",
    "    \n",
    "    # Calculate prediction confidence interval\n",
    "    pred_ci = result.get_prediction(X_sorted).conf_int(alpha=0.05)\n",
    "    \n",
    "    plt.fill_between(\n",
    "        x_sorted,\n",
    "        pred_ci[:, 0],\n",
    "        pred_ci[:, 1],\n",
    "        alpha=0.2, color='red'\n",
    "    )\n",
    "    \n",
    "    # Add annotations\n",
    "    plt.title(f\"Relationship between {target_name} and {predictor_name}\", fontsize=14)\n",
    "    plt.xlabel(predictor_name, fontsize=12)\n",
    "    plt.ylabel(target_name, fontsize=12)\n",
    "    \n",
    "    # Add regression equation and R²\n",
    "    eq_text = f\"y = {result.params[1]:.4f}x + {result.params[0]:.4f}\"\n",
    "    r2_text = f\"R² = {result.rsquared:.4f}\"\n",
    "    p_text = f\"p-value = {result.pvalues[1]:.4f}\"\n",
    "    \n",
    "    plt.annotate(eq_text + '\\n' + r2_text + '\\n' + p_text, \n",
    "                xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"white\", alpha=0.8),\n",
    "                va='top')\n",
    "    \n",
    "    plt.grid(linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, f\"regression_{target}_vs_{predictor}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Save main regression results\n",
    "pd.DataFrame([\n",
    "    {\n",
    "        'target': k.split(' ~ ')[0],\n",
    "        'predictor': k.split(' ~ ')[1],\n",
    "        'coefficient': v['coefficient'],\n",
    "        'p_value': v['p_value'],\n",
    "        'r_squared': v['r_squared']\n",
    "    }\n",
    "    for k, v in regression_results.items()\n",
    "]).to_csv(os.path.join(MODELS_DIR, \"regression_results.csv\"), index=False)\n",
    "\n",
    "#####################################################\n",
    "# 2. Panel Data Analysis - Control for Country and Time Fixed Effects\n",
    "#####################################################\n",
    "print(\"\\n\\n2. Performing panel data analysis...\")\n",
    "\n",
    "# Create data for panel analysis (add country and year dummy variables)\n",
    "panel_df = wide_df.copy()\n",
    "\n",
    "# Convert countries to dummy variables\n",
    "panel_df = pd.get_dummies(panel_df, columns=['country_code'], drop_first=True)\n",
    "\n",
    "# For each indicator, perform panel regression analysis\n",
    "panel_results = {}\n",
    "\n",
    "for target in indicator_codes:\n",
    "    predictors = [ind for ind in indicator_codes if ind != target]\n",
    "    \n",
    "    # Prepare dataset\n",
    "    y = panel_df[target]\n",
    "    \n",
    "    # Basic model (without fixed effects)\n",
    "    X_basic = panel_df[predictors].copy()\n",
    "    X_basic = sm.add_constant(X_basic)\n",
    "    basic_model = sm.OLS(y, X_basic)\n",
    "    basic_result = basic_model.fit()\n",
    "    \n",
    "    # Fixed effects model (add country dummy variables)\n",
    "    country_dummies = [col for col in panel_df.columns if col.startswith('country_code_')]\n",
    "    X_fe = panel_df[predictors + country_dummies].copy()\n",
    "    for col in X_fe.columns:\n",
    "        X_fe[col] = pd.to_numeric(X_fe[col], errors='coerce')\n",
    "    y = pd.to_numeric(panel_df[target], errors='coerce')\n",
    "\n",
    "    df_model = pd.DataFrame({'y': y}).join(X_fe)\n",
    "    df_model = df_model.dropna()\n",
    "    y_clean = df_model['y']\n",
    "    X_clean = df_model.drop(columns=['y'])\n",
    "\n",
    "    X_clean = sm.add_constant(X_clean)\n",
    "    X_clean = X_clean.astype(float)\n",
    "    y_clean = y_clean.astype(float)\n",
    "\n",
    "    fe_result = sm.OLS(y_clean, X_clean).fit()\n",
    "    \n",
    "    # Time trend model (add year as a linear trend)\n",
    "    X_trend = panel_df[predictors + country_dummies + ['year']].copy()\n",
    "    X_trend = sm.add_constant(X_trend)\n",
    "\n",
    "    X_trend = X_trend.astype(float)\n",
    "    y_trend = pd.to_numeric(panel_df[target], errors='coerce').astype(float)\n",
    "\n",
    "    df_trend = pd.concat([y_trend.rename(target), X_trend], axis=1).dropna()\n",
    "    y_trend_clean = df_trend[target]\n",
    "    X_trend_clean = df_trend.drop(columns=[target])\n",
    "\n",
    "    trend_result = sm.OLS(y_trend_clean, X_trend_clean).fit()\n",
    "    \n",
    "    panel_results[target] = {\n",
    "        'basic': basic_result,\n",
    "        'fixed_effects': fe_result,\n",
    "        'time_trend': trend_result\n",
    "    }\n",
    "    \n",
    "    # Print results summary\n",
    "    target_name = code_to_name.get(target, target)\n",
    "    print(f\"\\nTarget variable: {target} ({target_name})\")\n",
    "    print(f\"Basic model R²: {basic_result.rsquared:.4f}\")\n",
    "    print(f\"Fixed effects model R²: {fe_result.rsquared:.4f}\")\n",
    "    print(f\"Time trend model R²: {trend_result.rsquared:.4f}\")\n",
    "\n",
    "# Save panel regression results\n",
    "for target, models in panel_results.items():\n",
    "    target_name = code_to_name.get(target, target)\n",
    "    \n",
    "    # Create a comparison table\n",
    "    coef_table = pd.DataFrame()\n",
    "    \n",
    "    # For each predictor, extract coefficients and p-values\n",
    "    predictors = [ind for ind in indicator_codes if ind != target]\n",
    "    \n",
    "    for predictor in predictors:\n",
    "        predictor_name = code_to_name.get(predictor, predictor)\n",
    "        \n",
    "        # Extract coefficients and p-values by predictor name\n",
    "        coef_basic = models['basic'].params.get(predictor, np.nan)\n",
    "        p_basic    = models['basic'].pvalues.get(predictor, np.nan)\n",
    "\n",
    "        coef_fe    = models['fixed_effects'].params.get(predictor, np.nan)\n",
    "        p_fe       = models['fixed_effects'].pvalues.get(predictor, np.nan)\n",
    "\n",
    "        coef_trend = models['time_trend'].params.get(predictor, np.nan)\n",
    "        p_trend    = models['time_trend'].pvalues.get(predictor, np.nan)\n",
    "        \n",
    "        # Add to table\n",
    "        row = {\n",
    "            'Predictor': predictor_name,\n",
    "            'Basic Model_Coefficient': coef_basic,\n",
    "            'Basic Model_p-value': p_basic,\n",
    "            'Fixed Effects_Coefficient': coef_fe,\n",
    "            'Fixed Effects_p-value': p_fe,\n",
    "            'Time Trend_Coefficient': coef_trend,\n",
    "            'Time Trend_p-value': p_trend\n",
    "        }\n",
    "        coef_table = pd.concat([coef_table, pd.DataFrame([row])], ignore_index=True)\n",
    "    \n",
    "    # Add model information\n",
    "    info_row = {\n",
    "        'Predictor': 'Model Information',\n",
    "        'Basic Model_Coefficient': f\"R²: {models['basic'].rsquared:.4f}\",\n",
    "        'Basic Model_p-value': f\"Adj R²: {models['basic'].rsquared_adj:.4f}\",\n",
    "        'Fixed Effects_Coefficient': f\"R²: {models['fixed_effects'].rsquared:.4f}\",\n",
    "        'Fixed Effects_p-value': f\"Adj R²: {models['fixed_effects'].rsquared_adj:.4f}\",\n",
    "        'Time Trend_Coefficient': f\"R²: {models['time_trend'].rsquared:.4f}\",\n",
    "        'Time Trend_p-value': f\"Adj R²: {models['time_trend'].rsquared_adj:.4f}\"\n",
    "    }\n",
    "    coef_table = pd.concat([coef_table, pd.DataFrame([info_row])], ignore_index=True)\n",
    "    \n",
    "    # Save table\n",
    "    coef_table.to_csv(os.path.join(MODELS_DIR, f\"panel_results_{target}.csv\"), index=False)\n",
    "    \n",
    "    # Visualize model comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot original data\n",
    "    for country in df['country_code'].unique():\n",
    "        country_data = wide_df[wide_df['country_code'] == country]\n",
    "        plt.scatter(country_data['year'], country_data[target], alpha=0.7, label=country if len(df['country_code'].unique()) <= 5 else None)\n",
    "    \n",
    "    # Plot different model predictions\n",
    "    sorted_data = panel_df.sort_values(['year'])\n",
    "    \n",
    "    # Predict basic model\n",
    "    y_pred_basic = models['basic'].predict(X_basic)\n",
    "    \n",
    "    # Plot basic model prediction\n",
    "    plt.plot(sorted_data['year'], y_pred_basic, 'r-', linewidth=2, label='Basic Model')\n",
    "    \n",
    "    plt.title(f\"{target_name} - Panel Data Models\", fontsize=14)\n",
    "    plt.xlabel(\"Year\", fontsize=12)\n",
    "    plt.ylabel(target_name, fontsize=12)\n",
    "    plt.legend(title=\"Model/Country\")\n",
    "    plt.grid(linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, f\"panel_models_{target}.png\"))\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
